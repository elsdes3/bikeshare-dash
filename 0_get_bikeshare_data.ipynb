{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42fbdc5c-478e-4d84-a57d-5bae14ac5fea",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4a2b6-b5e2-47f0-8271-ba70068fc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c066a-ac15-4280-b4a3-1ad48d2fc39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "from multiprocessing import cpu_count\n",
    "from typing import Dict, List\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "from joblib import Parallel, delayed\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d539235-2669-406c-9919-7eae35ecabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.utils\n",
    "from src.utils import summarize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aedd86-d28d-45c5-b8bb-8d0d1df93f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "# # Open Data Portal\n",
    "url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca/api/3/action/package_show\"\n",
    "# # Ridership\n",
    "params = {\"id\": \"7e876c24-177c-4605-9cef-e50dd74c617f\"}\n",
    "# # Stations Metadata\n",
    "about_params = {\"id\": \"2b44db0d-eea9-442d-b038-79335368ad5a\"}\n",
    "\n",
    "# Name of database table to store merged hourly aggregated data\n",
    "table_name = \"ridership\"\n",
    "\n",
    "# Ridership dtypes dict\n",
    "dtypes_dict = {\n",
    "    \"Trip Duration\": int,\n",
    "    \"Start Station Id\": int,\n",
    "    \"End Station Id\": float,\n",
    "    \"Bike Id\": float,\n",
    "}\n",
    "\n",
    "# Neighbourhood GeoData columns to keep when getting neighbourhood\n",
    "# containing a location\n",
    "geo_cols = [\"AREA_NAME\", \"geometry\", \"Shape__Area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71f21d-b37a-44f3-a173-cc222bed5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"../sql.ini\")\n",
    "default_cfg = config[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6357c9-1473-4fce-bac6-f3b8b60872e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_TYPE = default_cfg[\"DB_TYPE\"]\n",
    "DB_DRIVER = default_cfg[\"DB_DRIVER\"]\n",
    "DB_USER = default_cfg[\"DB_USER\"]\n",
    "DB_PASS = default_cfg[\"DB_PASS\"]\n",
    "DB_HOST = default_cfg[\"DB_HOST\"]\n",
    "DB_PORT = default_cfg[\"DB_PORT\"]\n",
    "DB_NAME = \"bikeshare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a7aaa-0e41-43c7-888a-211bc09ba495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to single database (required to create database)\n",
    "URI_NO_DB = f\"{DB_TYPE}+{DB_DRIVER}://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}\"\n",
    "\n",
    "# Connect to all databases (required to perform CRUD operations and submit queries)\n",
    "URI = f\"{DB_TYPE}+{DB_DRIVER}://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d952a2-f504-4308-a0af-b5076ba900ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_urls(main_dataset_url: str, dataset_params: Dict) -> List:\n",
    "    package = requests.get(main_dataset_url, params=dataset_params).json()\n",
    "    resources = package[\"result\"][\"resources\"]\n",
    "    df = pd.DataFrame.from_records(resources)\n",
    "    year_month_wanted = [\n",
    "        f\"{y}-{str(m).zfill(2)}\" for y in [2021] for m in range(1, 10 + 1)\n",
    "    ]\n",
    "    year_month_wanted_str = \"|\".join(year_month_wanted)\n",
    "    urls_list = df.query(\"name.str.contains(@year_month_wanted_str)\")[\"url\"].tolist()\n",
    "    return urls_list\n",
    "\n",
    "\n",
    "def read_data(url: str, dtypes_dict: Dict) -> pd.DataFrame:\n",
    "    df = pd.read_csv(\n",
    "        url,\n",
    "        encoding=\"cp1252\",\n",
    "        parse_dates=[\"Start Time\", \"End Time\"],\n",
    "        dtype=dtypes_dict,\n",
    "    )\n",
    "    df = df.rename(columns={list(df)[0]: \"Trip Id\"})\n",
    "    df.columns = df.columns.str.replace(\"  \", \" \").str.replace(\" \", \"_\").str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "def load(df: pd.DataFrame, table_name: str, uri: str) -> None:\n",
    "    engine = create_engine(URI)\n",
    "    conn = engine.connect()\n",
    "    df_stations.to_sql(table_name, index=False, con=conn, if_exists=\"append\")\n",
    "    conn.close()\n",
    "    engine.dispose()\n",
    "\n",
    "\n",
    "def get_single_ridership_data_file(url: str, dtypes_dict: Dict) -> pd.DataFrame:\n",
    "    fname = os.path.basename(url)\n",
    "    print(f\"Loading data from {fname}...\", end=\"\")\n",
    "    df = read_data(url, dtypes_dict)\n",
    "    print(\"Done.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_all_data_files(urls_list: List, dtypes_dict: Dict) -> pd.DataFrame:\n",
    "    executor = Parallel(n_jobs=cpu_count(), backend=\"multiprocessing\")\n",
    "    tasks = (\n",
    "        delayed(get_single_ridership_data_file)(url, dtypes_dict) for url in urls_list\n",
    "    )\n",
    "    dfs = executor(tasks)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_stations_metadata(stations_url: str, stations_params: Dict) -> pd.DataFrame:\n",
    "    package = requests.get(stations_url, params=about_params).json()\n",
    "    resources = package[\"result\"][\"resources\"]\n",
    "    df_about = pd.DataFrame.from_records(resources)\n",
    "    r = requests.get(df_about[\"url\"].tolist()[0]).json()\n",
    "    url_stations = r[\"data\"][\"en\"][\"feeds\"][2][\"url\"]\n",
    "    df_stations = pd.DataFrame.from_records(\n",
    "        requests.get(url_stations).json()[\"data\"][\"stations\"]\n",
    "    )\n",
    "    return df_stations\n",
    "\n",
    "\n",
    "def transform_metadata(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"station_id\"] = df[\"station_id\"].astype(int)\n",
    "    dfa = pd.DataFrame(\n",
    "        df.set_index(\"station_id\")[\"rental_methods\"].tolist(),\n",
    "        columns=[\"key\", \"transitcard\", \"creditcard\", \"phone\"],\n",
    "    )\n",
    "    for c in [\"KEY\", \"TRANSITCARD\", \"CREDITCARD\", \"PHONE\"]:\n",
    "        dfa[c.lower()] = dfa[c.lower()].map({c: 1}).fillna(0).astype(int)\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df.drop(columns=[\"groups\", \"rental_methods\"]),\n",
    "            dfa,\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).rename(columns={\"key\": \"physicalkey\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_toronto_open_data(url, params, col_rename_dict={}):\n",
    "    package = requests.get(url, params=params).json()\n",
    "    datastore_url = (\n",
    "        \"https://ckan0.cf.opendata.inter.prod-toronto.ca/api/3/\"\n",
    "        \"action/datastore_search\"\n",
    "    )\n",
    "    for _, resource in enumerate(package[\"result\"][\"resources\"]):\n",
    "        if resource[\"datastore_active\"]:\n",
    "            url = datastore_url\n",
    "            p = {\"id\": resource[\"id\"]}\n",
    "            data = requests.get(url, params=p).json()\n",
    "            df = pd.DataFrame(data[\"result\"][\"records\"])\n",
    "            break\n",
    "    if col_rename_dict:\n",
    "        df = df.rename(columns=col_rename_dict)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_lat_long(row):\n",
    "    return row[\"coordinates\"]\n",
    "\n",
    "\n",
    "def get_poi_data(url: str, params: Dict) -> pd.DataFrame:\n",
    "    poi_cols = [\n",
    "        \"ID\",\n",
    "        \"NAME\",\n",
    "        \"PLACE_NAME\",\n",
    "        \"ADDRESS_FULL\",\n",
    "        \"POSTAL_CODE\",\n",
    "        \"ATTRACTION_DESC\",\n",
    "        \"POI_LATITUDE\",\n",
    "        \"POI_LONGITUDE\",\n",
    "    ]\n",
    "    package = requests.get(url, params=poi_params).json()\n",
    "    poi_url = package[\"result\"][\"resources\"][0][\"url\"]\n",
    "    df = pd.read_csv(poi_url)\n",
    "    assert len(df) == 175\n",
    "    df[[\"POI_LONGITUDE\", \"POI_LATITUDE\"]] = pd.DataFrame(\n",
    "        df[\"geometry\"].apply(eval).apply(get_lat_long).tolist()\n",
    "    )\n",
    "    # Verify no duplicates (by name) are in the data\n",
    "    assert df[df.duplicated(subset=[\"NAME\"], keep=False)].empty\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_cultural_hotspots(url: str, params: Dict) -> pd.DataFrame:\n",
    "    package = requests.get(url, params=params).json()\n",
    "    ch_locations = package[\"result\"][\"resources\"][0][\"url\"]\n",
    "    ch_locs_dir_path = \"data/raw/cultural-hotspot-points-of-interest-wgs84\"\n",
    "    with urlopen(ch_locations) as zipresp:\n",
    "        with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "            zfile.extractall(ch_locs_dir_path)\n",
    "    df = gpd.read_file(f\"{ch_locs_dir_path}/CULTURAL_HOTSPOT_WGS84.shp\")\n",
    "    df = (\n",
    "        df.drop_duplicates(\n",
    "            subset=[\"PNT_OF_INT\", \"LATITUDE\", \"LONGITUDE\"],\n",
    "            keep=\"first\",\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "    df = (\n",
    "        df.drop_duplicates(\n",
    "            subset=[\"PNT_OF_INT\"],\n",
    "            keep=\"first\",\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "    assert df[df.duplicated(subset=[\"PNT_OF_INT\"], keep=False)].empty\n",
    "    df_essentials = df[[\"RID\", \"PNT_OF_INT\", \"LATITUDE\", \"LONGITUDE\"]].rename(\n",
    "        columns={\n",
    "            \"RID\": \"ID\",\n",
    "            \"PNT_OF_INT\": \"NAME\",\n",
    "            \"LATITUDE\": \"POI_LATITUDE\",\n",
    "            \"LONGITUDE\": \"POI_LONGITUDE\",\n",
    "        }\n",
    "    )\n",
    "    return df_essentials\n",
    "\n",
    "\n",
    "def get_neighbourhood_boundary_land_area_data(url: str, params: Dict) -> pd.DataFrame:\n",
    "    package = requests.get(url, params=params).json()\n",
    "    n_url = (\n",
    "        package[\"result\"][\"resources\"][0][\"url\"].replace(\n",
    "            \"datastore/dump\", \"download_resource\"\n",
    "        )\n",
    "        + \"?format=geojson&projection=4326\"\n",
    "    )\n",
    "    gdf = gpd.read_file(n_url)\n",
    "    gdf[\"centroid\"] = gdf[\"geometry\"].to_crs(epsg=3395).centroid.to_crs(epsg=4326)\n",
    "    gdf[\"AREA_LATITUDE\"] = gdf[\"centroid\"].y\n",
    "    gdf[\"AREA_LONGITUDE\"] = gdf[\"centroid\"].x\n",
    "    assert len(gdf) == 140\n",
    "    neigh_cols_to_show = [\n",
    "        \"AREA_ID\",\n",
    "        \"AREA_SHORT_CODE\",\n",
    "        \"AREA_LONG_CODE\",\n",
    "        \"AREA_NAME\",\n",
    "        \"Shape__Area\",\n",
    "        \"LATITUDE\",\n",
    "        \"AREA_LATITUDE\",\n",
    "        \"LONGITUDE\",\n",
    "        \"AREA_LONGITUDE\",\n",
    "    ]\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def get_public_transit_locations(url: str, params: Dict) -> pd.DataFrame:\n",
    "    package = requests.get(url, params=params).json()\n",
    "    pt_locations = package[\"result\"][\"resources\"][0][\"url\"]\n",
    "    pt_locs_dir_path = \"data/raw/opendata_ttc_schedules\"\n",
    "    with urlopen(pt_locations) as zipresp:\n",
    "        with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "            zfile.extractall(pt_locs_dir_path)\n",
    "    df_pt = pd.read_csv(f\"{pt_locs_dir_path}/stops.txt\")\n",
    "    display(df_pt.head())\n",
    "    df_pt = df_pt.rename(columns={\"stop_lat\": \"lat\", \"stop_lon\": \"lon\"})\n",
    "    return df_pt\n",
    "\n",
    "\n",
    "def get_coll_univ_locations() -> pd.DataFrame:\n",
    "    coll_univ_locations = {\n",
    "        \"centennial\": {\"lat\": 43.7854, \"lon\": -79.22664},\n",
    "        \"george-brown\": {\"lat\": 43.6761, \"lon\": -79.4111},\n",
    "        \"humber\": {\"lat\": 43.7290, \"lon\": -79.6074},\n",
    "        \"ocad\": {\"lat\": 43.6530, \"lon\": -79.3912},\n",
    "        \"ryerson\": {\"lat\": 43.6577, \"lon\": -79.3788},\n",
    "        \"seneca\": {\"lat\": 43.7955, \"lon\": -79.3496},\n",
    "        \"tynedale\": {\"lat\": 43.7970, \"lon\": -79.3945},\n",
    "        \"uoft-scarborough\": {\"lat\": 43.7844, \"lon\": -79.1851},\n",
    "        \"uoft\": {\"lat\": 43.6629, \"lon\": -79.5019},\n",
    "        \"yorku\": {\"lat\": 43.7735, \"lon\": -79.5019},\n",
    "        \"yorku-glendon\": {\"lat\": 43.7279, \"lon\": -79.3780},\n",
    "    }\n",
    "    df_coll_univ = (\n",
    "        pd.DataFrame.from_dict(coll_univ_locations, orient=\"index\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"institution_name\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"institution_id\"})\n",
    "    )\n",
    "    return df_coll_univ\n",
    "\n",
    "\n",
    "def get_neighbourhood_profile_data(url: str, params: Dict) -> pd.DataFrame:\n",
    "    df_neigh_demog = get_toronto_open_data(url, params)\n",
    "    df_neigh_demog = (\n",
    "        df_neigh_demog[\n",
    "            df_neigh_demog[\"Characteristic\"].isin(\n",
    "                [\n",
    "                    \"Neighbourhood Number\",\n",
    "                    \"Youth (15-24 years)\",\n",
    "                    \"Working Age (25-54 years)\",\n",
    "                    \"Population, 2016\",\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "        .iloc[:, slice(4, None)]\n",
    "        .set_index(\"Characteristic\")\n",
    "        .T.reset_index()\n",
    "        .iloc[1:]\n",
    "        .reset_index(drop=True)\n",
    "        .rename(columns={\"index\": \"name\"})\n",
    "    )\n",
    "    assert len(df_neigh_demog) == 140\n",
    "    df_neigh_demog[\"AREA_NAME\"] = (\n",
    "        df_neigh_demog[\"name\"] + \" (\" + df_neigh_demog[\"Neighbourhood Number\"] + \")\"\n",
    "    )\n",
    "    return df_neigh_demog\n",
    "\n",
    "\n",
    "def get_neighbourhood_containing_point(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    df: pd.DataFrame,\n",
    "    lat: str = \"Latitude\",\n",
    "    lon: str = \"Longitude\",\n",
    "    crs: int = 4326,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    cols_order = list(df) + list(gdf)\n",
    "    polygons_contains = (\n",
    "        gpd.sjoin(\n",
    "            gdf,\n",
    "            gpd.GeoDataFrame(\n",
    "                df, geometry=gpd.points_from_xy(df[lon], df[lat]), crs=crs\n",
    "            ),\n",
    "            predicate=\"contains\",\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "        .drop(columns=[\"index_right\"])[cols_order]\n",
    "    )\n",
    "    # print(polygons_contains)\n",
    "    return polygons_contains\n",
    "\n",
    "\n",
    "def get_data_with_neighbourhood(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    df: pd.DataFrame,\n",
    "    lat: int,\n",
    "    lon: int,\n",
    "    col_to_join: str,\n",
    "    crs: int = 4326,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    cols_to_keep = [col_to_join, \"AREA_NAME\", \"geometry\", \"Shape__Area\"]\n",
    "    df_check = get_neighbourhood_containing_point(gdf, df, lat, lon, crs)[cols_to_keep]\n",
    "    display(df_check.head(2))\n",
    "    df = df.merge(df_check.drop(columns=[\"geometry\"]), on=col_to_join, how=\"left\").drop(\n",
    "        columns=[\"geometry\"]\n",
    "    )\n",
    "    print(\n",
    "        f\"Dropped {len(df[['AREA_NAME']].isna().sum())} rows with a missing AREA_NAME\"\n",
    "    )\n",
    "    df = df.dropna(subset=[\"AREA_NAME\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d822b36-cac4-4e5f-804b-8310fb5f25af",
   "metadata": {},
   "source": [
    "## Get Bikeshare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5d1270-b1f3-4739-b635-f535b04a993e",
   "metadata": {},
   "source": [
    "### Get List of Ridership URLs from Open Data Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73e2a7-6bfa-40b9-82b9-faac3927f245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_urls = get_file_urls(url, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2613bd6-5e64-4305-83a7-7c838eade7c4",
   "metadata": {},
   "source": [
    "### Retrieve Ridership Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20f5ff-adf3-490f-b884-8b3e5ddbd980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = get_all_data_files(all_urls, dtypes_dict)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d018a-f4d2-4376-a4aa-474cd1e283cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract attributes\n",
    "# # Trip duration\n",
    "df[\"duration\"] = (df[\"end_time\"] - df[\"start_time\"]).dt.seconds\n",
    "# # Datetime attributes\n",
    "for trip_point in [\"start\", \"end\"]:\n",
    "    df[f\"{trip_point}_year\"] = df[f\"{trip_point}_time\"].dt.year\n",
    "    df[f\"{trip_point}_month\"] = df[f\"{trip_point}_time\"].dt.month\n",
    "    df[f\"{trip_point}_day\"] = df[f\"{trip_point}_time\"].dt.day\n",
    "    df[f\"{trip_point}_hour\"] = df[f\"{trip_point}_time\"].dt.hour\n",
    "    df[f\"{trip_point}_minute\"] = df[f\"{trip_point}_time\"].dt.minute\n",
    "    df[f\"{trip_point}_quarter\"] = df[f\"{trip_point}_time\"].dt.quarter\n",
    "display(df)\n",
    "summarize_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295a323-eb4f-4483-afbc-e564433ed987",
   "metadata": {},
   "source": [
    "### Drop Rows with Missing Values and Duplicates from Ridership Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f47e4c-007e-4063-a9f9-2e6cb0302c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in which to drop missing values\n",
    "nan_cols = [\n",
    "    \"start_station_id\",\n",
    "    \"end_station_id\",\n",
    "    \"start_station_name\",\n",
    "    \"end_station_name\",\n",
    "]\n",
    "\n",
    "# Columns with duplicates, in which to drop rows\n",
    "duplicated_cols = [\"trip_id\", \"start_time\", \"end_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d1abc-4e58-48c2-91b4-8a29523bde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dups_to_drop = df.dropna(subset=nan_cols)[\n",
    "    df.dropna(subset=nan_cols).duplicated(subset=duplicated_cols, keep=\"first\")\n",
    "]\n",
    "not_missing = len(df.dropna(subset=nan_cols))\n",
    "d_nan = {\n",
    "    \"all\": len(df),\n",
    "    \"non_missing\": not_missing,\n",
    "    \"frac_to_drop\": ((len(df) - not_missing) / len(df)) * 100,\n",
    "    \"duplicates_to_drop\": (len(dups_to_drop) / len(df)) * 100,\n",
    "}\n",
    "df_nan = pd.DataFrame.from_dict(d_nan, orient=\"index\").T\n",
    "summarize_df(df)\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03666962-43be-4ac9-8ba9-ed1cacaa3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = df.dropna(subset=nan_cols).drop_duplicates(subset=duplicated_cols, keep=\"first\")\n",
    "summarize_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeba487-a724-44e8-8f35-b0ebfd51696d",
   "metadata": {},
   "source": [
    "### Get Stations Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5bf358-5d14-44d2-b9c6-bc8904b0083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_stations = get_stations_metadata(url, about_params)\n",
    "df_stations = transform_metadata(df_stations)\n",
    "df_stations.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52246e-db8e-4d49-9a37-dac36681cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c4e9d3-b983-4850-beca-f7551aa01f32",
   "metadata": {},
   "source": [
    "## Get Supplementary Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf46fc43-83c4-4433-a6f4-7f5df0ad8bc5",
   "metadata": {},
   "source": [
    "### Cultural Hotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010cefb-db6a-4a58-9d99-7c173ec541a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params = {\"id\": \"c7be2ee7-d317-4a28-8cbe-bff1ce116b46\"}\n",
    "dfch_essentials = get_cultural_hotspots(url, params)\n",
    "dfch_essentials.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1181f5ef-0c2f-4395-93de-e5f2873fd97d",
   "metadata": {},
   "source": [
    "### Places of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e8624-2b71-4f24-91f7-38b4262a360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "poi_params = {\"id\": \"965247c0-c72e-49b4-bb1a-879cf98e1a32\"}\n",
    "df_poi = get_poi_data(url, poi_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99111d64-9acd-4cf2-98eb-970d8293416a",
   "metadata": {},
   "source": [
    "Note that duplicate lat-long will be permitted here as multiple places of interest may share the same physical location, or immediately adjacent area. Such places of interest with a duplicated latitude and longitde are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dada67-9c93-41f8-ba8e-166b69455181",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df_poi[df_poi.duplicated(subset=[\"POI_LATITUDE\", \"POI_LONGITUDE\"], keep=False)][\n",
    "        [\"ID\", \"NAME\", \"POI_LATITUDE\", \"POI_LONGITUDE\"]\n",
    "    ]\n",
    "    .sort_values(by=[\"POI_LATITUDE\", \"POI_LONGITUDE\"])\n",
    "    .style.set_caption(\"Duplicates of Latitude-Longitude\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fff15ec-f069-47e1-b088-bf520eda3656",
   "metadata": {},
   "source": [
    "These duplicated lat-long locations are shown below to be different points of interest based at the same site\n",
    "- `ID`=40, `ID`=42\n",
    "  - Enercare Centre and Exhibition Place are at the same site\n",
    "- 57, 171\n",
    "  - York Quay Centre [is at](https://www.museumsontario.ca/museum/York-Quay-Centre-at-Harbourfro) the HarborFront Centre\n",
    "- 66, 70\n",
    "  - both places are based at the the Ferry Terminal, so can correctly have the same lat-long\n",
    "- 68, 124, 154\n",
    "  - the Brewery and the Toronto Railway Museum are based at Roundhouse Park\n",
    "- 24, 54\n",
    "  - [Glenn Gould Studio](https://www.cbc.ca/glenngouldstudio/) is based at the CBC Museum\n",
    "- 157, 160, 162\n",
    "  - the [Tourist Information Centre](https://www.toronto.ca/explore-enjoy/visitor-services/tourist-information-centres/) is at the same site as the [Traveller's Aid Society](http://travellersaid.ca/contact.html) and [Union Station](https://torontounion.ca/contact/)\n",
    "- 67, 145\n",
    "  - a tourist information centre that is also baed at Nathan Phillips Square\n",
    "- 8, 167\n",
    "  - [Ashbridges Bay Park](https://www.toronto.ca/data/parks/prd/facilities/complex/1/index.html) is along [Woodbine Beach](https://www.toronto.ca/data/parks/prd/facilities/complex/311/index.html)\n",
    "- 75, 111\n",
    "  - Koerner Hall is at the Royal Observatory of Music\n",
    "- 73, 74\n",
    "  - [Kew Balmy Beach](https://www.tripadvisor.ca/Attraction_Review-g155019-d14788092-Reviews-Kew_Balmy_Beach-Toronto_Ontario.html#MAPVIEW-14788092) is at the same site as [Kew Gardens Park](https://www.toronto.ca/data/parks/prd/facilities/complex/107/index.html)\n",
    "- 93, 141\n",
    "  - both locations are at Todmorden Mills Park\n",
    "- 9, 21\n",
    "  - the Canadian Museum of Cultural Heritage of Indo-Canadians is based at the site of BAPS Shri Swaminarayan Mandir ([link](https://www.baps.org/cultureandheritage/ExperienceIndia/Exhibitions/CanadianMuseumofCulturalHeritageofIndo-Canadians.aspx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89861fb1-b065-46ea-bda1-1805b5f6b98c",
   "metadata": {},
   "source": [
    "So, the duplicate lat-long sites will be retained in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42caf32e-348d-4366-8777-e3b9c860e2d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Neighbourhood Boundary and Land Area Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bdb9cd-8973-458e-a28a-abd42170ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "neigh_params = {\"id\": \"4def3f65-2a65-4a4f-83c4-b2a4aed72d46\"}\n",
    "gdf = get_neighbourhood_boundary_land_area_data(url, neigh_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94968c91-d8b0-4605-8ddc-78f29e122ddc",
   "metadata": {},
   "source": [
    "Print the data for a few neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5101c-50fb-43b4-b9c8-322838b3c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_cols_to_show = [\n",
    "    \"AREA_ID\",\n",
    "    \"AREA_SHORT_CODE\",\n",
    "    \"AREA_LONG_CODE\",\n",
    "    \"AREA_NAME\",\n",
    "    \"Shape__Area\",\n",
    "    \"LATITUDE\",\n",
    "    \"AREA_LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"AREA_LONGITUDE\",\n",
    "]\n",
    "gdf[\n",
    "    gdf[\"AREA_NAME\"].str.contains(\n",
    "        \"Wychwood|Yonge-Eglinton|Yonge-St.|York Univ|Yorkdale-Glen\"\n",
    "    )\n",
    "][neigh_cols_to_show].sort_values(by=[\"AREA_NAME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29814281-d328-40ff-b5a4-dda3651abb61",
   "metadata": {},
   "source": [
    "In order to use the correct CRS for allowing an area calculation in square km, we'll get the current EPSG ([link](https://epsg.io/4326)) from the geodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc1cab-9d14-4fa4-90a6-fc302a7e2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bb43df-e4b4-41f4-a909-18242cc5a71a",
   "metadata": {},
   "source": [
    "Fix typographic errors in the name of the neighbourhood in this dataset\n",
    "- [North St. James Town](https://www.toronto.ca/ext/sdfa/Neighbourhood%20Profiles/pdf/2016/pdf1/cpa74.pdf) and [Cabbagetown-South St. James Town](https://www.toronto.com/community-static/4550668-cabbagetown-south-st-james-town/)\n",
    "  - missing space between ...St. and Ja...\n",
    "- Weston-Pelham Park\n",
    "  - incorrectly listed as its old name (from 2011) of Weston-Pellam Park ([link](https://www.toronto.ca/wp-content/uploads/2017/11/900b-91-Weston-Pellam-Park.pdf))\n",
    "  - replace with [new name from 2016](https://www.toronto.ca/ext/sdfa/Neighbourhood%20Profiles/pdf/2016/pdf1/cpa91.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ef134-638e-49bc-b8ce-854819f189f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_renaming = {\n",
    "    \"St.James\": \"St. James\",\n",
    "    \"Weston-Pellam\": \"Weston-Pelham\",\n",
    "}\n",
    "for k, v in d_renaming.items():\n",
    "    gdf[\"AREA_NAME\"] = gdf[\"AREA_NAME\"].str.replace(k, v, regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d007c1-d0e7-4ca7-8a1d-ea2ae40d19ca",
   "metadata": {},
   "source": [
    "The incorrect names have been successfully replaced as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db7588-abcd-4f2a-b651-96cf82e0c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighbourhood GeoData columns to use\n",
    "geo_cols = [\"AREA_NAME\", \"geometry\", \"Shape__Area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20be60-23b1-456b-b22f-e560f4b1af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.query(\"AREA_NAME.str.contains('James Town|Weston-|Cabbage')\")[geo_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3eafc-29eb-41f3-b0e8-83c9fe7c081b",
   "metadata": {},
   "source": [
    "Compare manual to provided neighbourhood areas (in square km)\n",
    "- first, changes geodata projection to a cartesian system (EPSG = 3857, in units of m) ([1](https://epsg.io/3857))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7921847-fd76-4ee5-8eea-5af30639c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_diff = (gdf[\"geometry\"].to_crs(epsg=3857).area) - gdf[\"Shape__Area\"]\n",
    "print(area_diff.min(), area_diff.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89617fe2-9489-4896-bac3-1d9227ff2b2c",
   "metadata": {},
   "source": [
    "Since these are small differences (in units of square km), we'll use the provided neighbourhood areas from the `Shape__Area` column of the neighbourhood boundary file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43cad7-4bf6-4c0e-88a6-a1e11a7b0730",
   "metadata": {},
   "source": [
    "### Public Transit Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c24c15-dbfb-4fe5-9a03-31feb418836f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "params = {\"id\": \"7795b45e-e65a-4465-81fc-c36b9dfff169\"}\n",
    "df_pt_slice = get_public_transit_locations(url, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ad1b1-96a1-4ebc-af6c-7f27c894df60",
   "metadata": {},
   "source": [
    "### Colleges and Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bae3bd-29cf-4598-b443-19d34a31b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coll_univ = get_coll_univ_locations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b494e296-f3b8-4bcd-9532-ec62beb6b834",
   "metadata": {},
   "source": [
    "### Neighbourhood Profile Data - Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d2cee-a0f9-4fd6-8cbf-2191872716dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "neigh_profile_params = {\"id\": \"6e19a90f-971c-46b3-852c-0c48c436d1fc\"}\n",
    "df_neigh_demog = get_neighbourhood_profile_data(url, neigh_profile_params)\n",
    "df_neigh_demog.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e5ff9-707e-4d54-ae6c-fbe212fe86cb",
   "metadata": {},
   "source": [
    "### Number of Locations Per Neighbourhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c42bd-5692-443e-b222-e8039f93db8a",
   "metadata": {},
   "source": [
    "#### Places of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d10663-5052-4fcf-96e2-3ea97a100068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_poi[\"ID\"].nunique(), len(df_poi))\n",
    "df_poi.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6d4fd-4592-4001-a9ed-39e98f1651a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_poi_new = get_data_with_neighbourhood(\n",
    "    gdf[geo_cols],\n",
    "    df_poi.rename(columns={\"POI_LATITUDE\": \"lat\", \"POI_LONGITUDE\": \"lon\",})[\n",
    "        [\"ID\", \"NAME\", \"lat\", \"lon\"]\n",
    "    ],\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"ID\",\n",
    ")\n",
    "display(df_poi_new.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f525adc-2d36-4332-9669-7f6463a7d10c",
   "metadata": {},
   "source": [
    "#### Cultural Hotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff522dc-2b0f-4c09-a3b0-7c0f9b5c9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfch_essentials[\"ID\"].nunique(), len(dfch_essentials))\n",
    "dfch_essentials.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0759fde-e80f-4fd9-86f2-1d9d66e53316",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfch_essentials_new = get_data_with_neighbourhood(\n",
    "    gdf[geo_cols],\n",
    "    dfch_essentials.rename(columns={\"POI_LATITUDE\": \"lat\", \"POI_LONGITUDE\": \"lon\",})[\n",
    "        [\"ID\", \"NAME\", \"lat\", \"lon\"]\n",
    "    ],\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"ID\",\n",
    ")\n",
    "display(dfch_essentials_new.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f5ac70-f563-4369-984d-0458ae9cd509",
   "metadata": {},
   "source": [
    "#### Colleges and Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92455c11-3eb4-493f-ba9d-325e47f22f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_coll_univ[\"institution_id\"].nunique(), len(df_coll_univ))\n",
    "df_coll_univ.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8a5b1-b2d1-4da1-ab06-ad0684ceab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_coll_univ_new = get_data_with_neighbourhood(\n",
    "    gdf[geo_cols],\n",
    "    df_coll_univ,\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"institution_id\",\n",
    ")\n",
    "display(df_coll_univ_new.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a438ede-7d87-4a1d-bdb3-3a063c78ccc7",
   "metadata": {},
   "source": [
    "#### Public Transit Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455362d3-9ee6-4a55-a1e8-5e26c01ba8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pt_slice[\"stop_id\"].nunique(), len(df_pt_slice))\n",
    "df_pt_slice.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec940e87-a9f2-48da-a37b-a41ceea89da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_pt_slice_new = get_data_with_neighbourhood(\n",
    "    gdf[geo_cols],\n",
    "    df_pt_slice,\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"stop_id\",\n",
    ")\n",
    "display(df_pt_slice_new.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b43c0c-3458-47bc-b196-5dcfd53643d7",
   "metadata": {},
   "source": [
    "#### Merge Neighbourhood Aggregations with GeoData and Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af454b-3435-4795-883a-a05f278c0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neigh_stats = (\n",
    "    (\n",
    "        gdf.set_index(\"AREA_NAME\")[\n",
    "            [\n",
    "                \"Shape__Area\",\n",
    "                \"Shape__Length\",\n",
    "                \"geometry\",\n",
    "                \"CLASSIFICATION\",\n",
    "                \"CLASSIFICATION_CODE\",\n",
    "                \"AREA_LATITUDE\",\n",
    "                \"AREA_LONGITUDE\",\n",
    "            ]\n",
    "        ]\n",
    "        .merge(\n",
    "            df_pt_slice_new.groupby(\"AREA_NAME\")[\"stop_id\"]\n",
    "            .count()\n",
    "            .rename(\"transit_stops\")\n",
    "            .to_frame(),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .merge(\n",
    "            df_coll_univ_new.groupby(\"AREA_NAME\")[\"institution_id\"]\n",
    "            .count()\n",
    "            .rename(\"colleges_univs\")\n",
    "            .to_frame(),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .merge(\n",
    "            dfch_essentials_new.groupby(\"AREA_NAME\")[\"ID\"]\n",
    "            .count()\n",
    "            .rename(\"cultural_attractions\")\n",
    "            .to_frame(),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .merge(\n",
    "            df_poi_new.groupby(\"AREA_NAME\")[\"ID\"]\n",
    "            .count()\n",
    "            .rename(\"places_of_interest\")\n",
    "            .to_frame(),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .fillna(0)\n",
    "        .astype(\n",
    "            {\n",
    "                k: int\n",
    "                for k in [\n",
    "                    \"transit_stops\",\n",
    "                    \"colleges_univs\",\n",
    "                    \"cultural_attractions\",\n",
    "                    \"places_of_interest\",\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        .merge(\n",
    "            df_neigh_demog.set_index(\"AREA_NAME\")[\n",
    "                [\"Population, 2016\", \"Youth (15-24 years)\", \"Working Age (25-54 years)\"]\n",
    "            ].rename(\n",
    "                columns={\n",
    "                    \"Population, 2016\": \"pop_2016\",\n",
    "                    \"Youth (15-24 years)\": \"youth_15_24\",\n",
    "                    \"Working Age (25-54 years)\": \"work_age_25_54\",\n",
    "                }\n",
    "            ),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    .add_prefix(\"neigh_\")\n",
    "    .rename(columns={\"neigh_geometry\": \"geometry\"})\n",
    ")\n",
    "df_neigh_stats.columns = df_neigh_stats.columns.str.lower().str.replace(\"__\", \"_\")\n",
    "df_neigh_stats = df_neigh_stats.reset_index()\n",
    "df_neigh_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2681e730-c6c3-4813-b205-a01028f9be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_neigh_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc57c1-e04c-44ed-9380-402ed4a8b03e",
   "metadata": {},
   "source": [
    "### Merge Stations Metadata with Aggregated Neighbourhood Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353e0f1-5c8f-4725-8a6b-78ac929ef196",
   "metadata": {},
   "source": [
    "Append the neighbourhood containing each bikeshare station to the station metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b31e2-1808-4f6e-a432-99939aca52be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_stations[\"station_id\"].nunique(), len(df_stations))\n",
    "df_stations.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5ac4c-076e-43f1-b1b4-71adaf367e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_stations_new = get_data_with_neighbourhood(\n",
    "    gdf[geo_cols],\n",
    "    df_stations[\n",
    "        [\"station_id\", \"name\", \"physical_configuration\", \"lat\", \"lon\", \"altitude\", \"address\", \"capacity\", \"physicalkey\", \"transitcard\", \"creditcard\", \"phone\"]\n",
    "    ],\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"station_id\",\n",
    ")\n",
    "display(df_stations_new.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e48fb-a7c3-4a55-89ae-91cbaddf02d7",
   "metadata": {},
   "source": [
    "Merge the modified stations metadata with the neighbourhood stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dae49a-da50-4a7e-a03b-d613a4901568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_new = (\n",
    "    df_stations_new.set_index(\"AREA_NAME\")\n",
    "    .merge(\n",
    "        df_neigh_stats.set_index(\"AREA_NAME\"),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df_stations_new.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b66c3b-8dd8-45f0-b3ee-43a88bab565c",
   "metadata": {},
   "source": [
    "## Merge Modified Stations Metadata With Ridership Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd2b36-33e8-4e92-8351-7e1514bfa96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregated_station_hourly_trips(\n",
    "    df: pd.DataFrame, cols: List, trip_point: str = \"start\"\n",
    ") -> pd.DataFrame:\n",
    "    trip_point_cols = [f\"{trip_point}_{c}\" for c in cols] + [\"user_type\"]\n",
    "    station_trips = df.groupby(trip_point_cols, as_index=False).agg(\n",
    "        {\"trip_id\": \"count\", \"duration\": [\"min\", \"median\", \"mean\", \"max\"]}\n",
    "    )\n",
    "    station_trips.columns = (\n",
    "        cols\n",
    "        + [\"user_type\"]\n",
    "        + [\n",
    "            \"num_trips\",\n",
    "            \"duration_min\",\n",
    "            \"duration_median\",\n",
    "            \"duration_mean\",\n",
    "            \"duration_max\",\n",
    "        ]\n",
    "    )\n",
    "    station_trips = (\n",
    "        station_trips.assign(station_type=trip_point)\n",
    "        .rename(columns={\"trip_id_count\": \"num_trips\"})\n",
    "        .sort_values(by=\"num_trips\", ascending=False)\n",
    "    )\n",
    "    return station_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8a58c-50f1-4d98-8598-dc419f31ab03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cols = [\"station_name\", \"year\", \"month\", \"day\", \"hour\"]\n",
    "df_hour_by_station_merged = pd.concat(\n",
    "    [\n",
    "        get_aggregated_station_hourly_trips(\n",
    "            df,\n",
    "            cols,\n",
    "            trip_point,\n",
    "        ).merge(\n",
    "            df_stations_new.rename(columns={\"name\": \"station_name\"}),\n",
    "            on=\"station_name\",\n",
    "            how=\"left\",\n",
    "        ).dropna(subset=[\"capacity\"])\n",
    "        for trip_point in [\"start\", \"end\"]\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "for c in [\"neigh_pop_2016\", \"neigh_youth_15_24\", \"neigh_work_age_25_54\"]:\n",
    "    df_hour_by_station_merged[c] = df_hour_by_station_merged[c].str.replace(\",\", \"\").astype(float)\n",
    "display(df_hour_by_station_merged.head(4).append(df_hour_by_station_merged.tail(4)))\n",
    "display(\n",
    "    df_hour_by_station_merged.isna().sum().rename(\"num_missing\").to_frame().merge(\n",
    "        df_hour_by_station_merged.dtypes.rename(\"dtype\").to_frame(), left_index=True, right_index=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede97b5-cba1-4d1e-85a1-63c81b89b69f",
   "metadata": {},
   "source": [
    "## Database Administration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae44e7-3983-486a-838e-f4b3c0b9b994",
   "metadata": {},
   "source": [
    "Create the `bikeshare` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809e6fa-4e40-4ef3-84e0-763ab95c096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(URI_NO_DB)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66f5ac-1876-4cab-9aac-78522a619f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = conn.execute(f\"DROP DATABASE IF EXISTS {DB_NAME};\")\n",
    "_ = conn.execute(f\"CREATE DATABASE IF NOT EXISTS {DB_NAME};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5c618-d75c-4272-a21a-8629055bb73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee39b1d8-496f-426d-9b71-56e8e7e734bc",
   "metadata": {},
   "source": [
    "## Create Database Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88540dc0-f186-4ed4-87c8-7319253800ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(URI)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6fb600-312e-4aca-b9da-d930a1d9f2b7",
   "metadata": {},
   "source": [
    "Create the `ridership` table in the `bikeshare` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780c12e-186e-441d-80de-ab0c28186598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd152c-76c3-4f45-a5c7-8d933a6d1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_table_query = f\"\"\"\n",
    "#                      CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "#                          station_name VARCHAR(100),\n",
    "#                          year INT,\n",
    "#                          month INT,\n",
    "#                          day INT,\n",
    "#                          hour INT,\n",
    "#                          user_type VARCHAR(20),\n",
    "#                          num_trips INT,\n",
    "#                          duration_min INT,\n",
    "#                          duration_median FLOAT,\n",
    "#                          duration_mean FLOAT,\n",
    "#                          duration_max INT,\n",
    "#                          station_type VARCHAR(10),\n",
    "#                          area_name TEXT,\n",
    "#                          station_id FLOAT,\n",
    "#                          physical_configuration TEXT,\n",
    "#                          lat FLOAT,\n",
    "#                          lon FLOAT,\n",
    "#                          altitude FLOAT,\n",
    "#                          address TEXT,\n",
    "#                          capacity INT,\n",
    "#                          physicalkey INT,\n",
    "#                          transitcard INT,\n",
    "#                          creditcard INT,\n",
    "#                          phone INT,\n",
    "#                          neigh_shape_area FLOAT,\n",
    "#                          neigh_shape_length FLOAT,\n",
    "#                          neigh_classification TEXT,\n",
    "#                          neigh_classification_code TEXT,\n",
    "#                          neigh_area_latitude FLOAT,\n",
    "#                          neigh_area_longitude FLOAT,\n",
    "#                          neigh_transit_stops INT,\n",
    "#                          neigh_colleges_univs INT,\n",
    "#                          neigh_cultural_attractions INT,\n",
    "#                          neigh_places_of_interest INT,\n",
    "#                          neigh_pop_2016 FLOAT,\n",
    "#                          neigh_youth_15_24 FLOAT,\n",
    "#                          neigh_work_age_25_54 FLOAT\n",
    "#                      )\n",
    "#                      \"\"\"\n",
    "# _ = conn.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400d918-1240-4387-b1cd-98a0bd44a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = conn.execute(\n",
    "    f\"ALTER TABLE {table_name} ADD UNIQUE unique_index(station_name, year, month, day, hour, user_type, station_type)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19770907-7a4b-4286-9adf-d25a28f3445e",
   "metadata": {},
   "source": [
    "## Append Merged Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c59e2-ebd6-4ffd-9b1f-9b1cdb51c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_hour_by_station_merged.drop(\n",
    "#     columns=[\"geometry\", \"Shape__Area\"]\n",
    "# ).iloc[0:10_000].to_sql(table_name, con=conn, index=False, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cd55ff-798d-43e5-b1e2-e7103dba1831",
   "metadata": {},
   "source": [
    "(NOT DONE HERE) Change the datatype for the neighbourhood stats columns to `INT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480356a-e8e3-4622-bca4-f0136330a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for c in [\"station_id\", \"neigh_pop_2016\", \"neigh_youth_15_24\", \"neigh_work_age_25_54\"]:\n",
    "#     _ = conn.execute(f\"ALTER TABLE {table_name} MODIFY {c} INTEGER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5a2daa-e15f-40f8-9e56-d9913107523b",
   "metadata": {},
   "source": [
    "Query the data in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7036f76-337a-40e6-813c-0f6db8e6d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_query = pd.read_sql(\n",
    "    f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {table_name}\n",
    "    WHERE station_type = 'start'\n",
    "    LIMIT 900000\n",
    "    \"\"\",\n",
    "    con=conn\n",
    ")\n",
    "df_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd9e02-1bc7-4f16-811b-ddaa2d316412",
   "metadata": {},
   "source": [
    "## Close MySQL Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7049c09-6f9a-4f3b-b773-f828ced2cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
